{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk import load\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that loads a lexicon of positive words to a set and returns the set\n",
    "def loadLexicon(fname):\n",
    "    newLex=set()\n",
    "    lex_conn=open(fname)\n",
    "    \n",
    "    #add every word in the file to the set\n",
    "    for line in lex_conn:\n",
    "        newLex.add(line.strip())# remember to strip to remove the lin-change character\n",
    "    lex_conn.close()\n",
    "\n",
    "    return newLex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpinions(input_file, feature_num):\n",
    "    \n",
    "    #load the positive and negative lexicons into sets\n",
    "    posLex=loadLexicon('positive-words.txt')\n",
    "    negLex=loadLexicon('negative-words.txt')\n",
    "\n",
    "    polarity_count={}#maps each noun to the number of times it appears in a negative sentence and to the number of times it appears in a positive sentence\n",
    "        \n",
    "    fin=open(input_file,encoding='utf8')\n",
    "\n",
    "    reader=csv.reader(fin)\n",
    "\n",
    "    for line in reader: # for each review\n",
    "\n",
    "        text,rating=line # get the text and rating\n",
    "    \n",
    "        sentences=sent_tokenize(text) # split the review into sentences\n",
    "\n",
    "        for sentence in sentences: # for each sentence\n",
    "        \n",
    "            words=word_tokenize(sentence) # split the review into words\n",
    "        \n",
    "            tagged_words=nltk.pos_tag(words) # POS tagging for the words in the sentence\n",
    "    \n",
    "            nouns_in_sentence=set() # set of all the nouns in the sentence\n",
    "        \n",
    "            positive_word_count=0 # number of positive words in the sentence\n",
    "            negative_word_count=0 # number of negative words in the sentence\n",
    "        \n",
    "            #https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "            for tagged_word in tagged_words:\n",
    "            \n",
    "                if tagged_word[1].startswith('NN'): # if the word is a noun\n",
    "\n",
    "                    noun=tagged_word[0].lower() # lower case the noun\n",
    "                    \n",
    "                    if len(noun)<3:continue # ignore nouns with less than 3 characters\n",
    "                                \n",
    "                    nouns_in_sentence.add(noun) # add the noun to the set\n",
    "                \n",
    "                    if noun not in polarity_count: # first time we see this noun\n",
    "                        polarity_count[noun]=[0,0] # positives, negatives\n",
    "                \n",
    "                if tagged_word[1].startswith('JJ') and tagged_word[0] in posLex: # if the word is in the positive lexicon\n",
    "                    positive_word_count+=1\n",
    "            \n",
    "                elif tagged_word[1].startswith('JJ') and tagged_word[0] in negLex: # if the word is in the negative lexicon\n",
    "                    negative_word_count+=1\n",
    "        \n",
    "            sentence_polarity=positive_word_count-negative_word_count\n",
    "        \n",
    "            if sentence_polarity>0: # positive sentence\n",
    "                for noun in nouns_in_sentence: # for each noun that we found in the sentence\n",
    "                    polarity_count[noun][0]+=1 #increase the positive count\n",
    "        \n",
    "            elif sentence_polarity<0: # negative sentence\n",
    "                for noun in nouns_in_sentence: # for each noun that we found in the sentence\n",
    "                    polarity_count[noun][1]+=1 #increase the negative count\n",
    "\n",
    "    fin.close()\n",
    "\n",
    "    #sort noun based on their total polarity counts (pos+neg)\n",
    "    sorted_polarity_count=sorted(polarity_count.items(),key=lambda x:x[1][0]+x[1][1],reverse=True)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    amazing->[30,5]\n",
    "    horrible->[4,35]\n",
    "    \n",
    "    [ ('amazing',[30,5]),  ('horrible',[4,35]) ]\n",
    "    \n",
    "    30+5, 4+35  \n",
    "    35,40\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #get the top feature_num features\n",
    "    top=sorted_polarity_count[:feature_num]\n",
    "\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sound', [78, 9])\n",
      "('headphones', [69, 12])\n",
      "('quality', [46, 6])\n",
      "('sennheiser', [35, 12])\n",
      "('bose', [29, 12])\n",
      "('anc', [30, 8])\n",
      "('noise', [25, 4])\n",
      "('bass', [26, 1])\n",
      "('momentum', [19, 4])\n",
      "('sony', [17, 6])\n",
      "('app', [16, 4])\n",
      "('music', [17, 3])\n",
      "('case', [11, 5])\n",
      "('battery', [10, 6])\n",
      "('time', [8, 5])\n"
     ]
    }
   ],
   "source": [
    "result=getOpinions('amazonreviews.csv',15)\n",
    "\n",
    "for noun in result:\n",
    "    print(noun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('battery', [10, 5]), ('price', [3, 8]), ('quality', [4, 2])]\n"
     ]
    }
   ],
   "source": [
    "D={'battery':[10,5],'quality':[4,2],'price':[3,8]}\n",
    "sortedD=sorted(D.items(),key=lambda x:x[1][0]+x[1][1],reverse=True)\n",
    "print(sortedD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Ted', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "_POS_TAGGER = 'taggers/maxent_treebank_pos_tagger/english.pickle'    \n",
    "tagger = load(_POS_TAGGER)\n",
    "\n",
    "sent='My name is Ted'\n",
    "words=word_tokenize(sent)\n",
    "tagged_words=tagger.tag(words)\n",
    "print(tagged_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
